# Web-Crawler
### Requirements
- pip install beautifulsoup4
- pip install selenium
- pip install xlsxwriter
- pip install pandas
- pip install nltk
- https://chromedriver.chromium.org/downloads
<sub> download chromedriver and place into any folder (no need to run .exe, just change file path in main.py to point to chromedriver.exe) </sub>
- Python 3.7
- Google Chrome

# LinkedIn Credentials
- Email: inf1002grp12@gmail.com
- Password: INF1002grp12!

#Update 2 by Kenrick
Added assets, pages, raw_data, venv folders (each folder has own py files).
Added dashboard.py.

- raw_data folder is the folder for scraped data from linkedin (haven't edit anything yet)
- assets folder contains data cleaning and processing
- pages folder with dashboard.py is mainly visualisation

To run:
- pip install -r requirements.txt
- py -m streamlit run dashboard.py


PM me if there is any issues
